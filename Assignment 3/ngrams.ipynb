{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(s, n):\n",
    "    ngrams=[]\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "    tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "    for i in range(len(tokens)-n):\n",
    "        s=\"\"\n",
    "        for j in range(n):\n",
    "            s+=tokens[i+j]+\" \"\n",
    "        ngrams.append(s[:-1])\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Write a program to compute unsmoothed unigrams, bigrams and Trigrams for a sequence of words. Generalize the \"\\\n",
    "\"programs for n-grams. Create a corpus by collecting 50 web news, Create a list of frequency of words and then build a \"\\\n",
    "\"Unigram, bigram and trigram language models, respectively. Use at least three sentences as input to test your \"\\\n",
    "\"language models with any two smoothing techniques. Also, make some performance analysis to explain which model and \"\\\n",
    "\"smoothing method is better.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = generate_ngrams(s,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['write a program', 'a program to', 'program to compute', 'to compute unsmoothed', 'compute unsmoothed unigrams', 'unsmoothed unigrams bigrams', 'unigrams bigrams and', 'bigrams and trigrams', 'and trigrams for', 'trigrams for a', 'for a sequence', 'a sequence of', 'sequence of words', 'of words generalize', 'words generalize the', 'generalize the programs', 'the programs for', 'programs for n', 'for n grams', 'n grams create', 'grams create a', 'create a corpus', 'a corpus by', 'corpus by collecting', 'by collecting 50', 'collecting 50 web', '50 web news', 'web news create', 'news create a', 'create a list', 'a list of', 'list of frequency', 'of frequency of', 'frequency of words', 'of words and', 'words and then', 'and then build', 'then build a', 'build a unigram', 'a unigram bigram', 'unigram bigram and', 'bigram and trigram', 'and trigram language', 'trigram language models', 'language models respectively', 'models respectively use', 'respectively use at', 'use at least', 'at least three', 'least three sentences', 'three sentences as', 'sentences as input', 'as input to', 'input to test', 'to test your', 'test your language', 'your language models', 'language models with', 'models with any', 'with any two', 'any two smoothing', 'two smoothing techniques', 'smoothing techniques also', 'techniques also make', 'also make some', 'make some performance', 'some performance analysis', 'performance analysis to', 'analysis to explain', 'to explain which', 'explain which model', 'which model and', 'model and smoothing', 'and smoothing method', 'smoothing method is']\n"
     ]
    }
   ],
   "source": [
    "print(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "from collections import Counter, defaultdict\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "snew = \"\"\n",
    "for string in reuters.sents():\n",
    "    snew += \" \".join(string)\n",
    "\n",
    "ngram = generate_ngrams(snew,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ngram)):\n",
    "    [w1, w2, w3] = ngram[i].split()\n",
    "    model[(w1, w2)][w3] += 1\n",
    "\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] = round((model[w1_w2][w3] / total_count),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 0.16,\n",
       " '0': 0.01,\n",
       " 'pilots': 0.01,\n",
       " 'iranian': 0.01,\n",
       " 'public': 0.01,\n",
       " 'bank': 0.06,\n",
       " 'european': 0.01,\n",
       " 'trade': 0.01,\n",
       " 'treasury': 0.01,\n",
       " 'price': 0.02,\n",
       " 'central': 0.05,\n",
       " 'mine': 0.01,\n",
       " 'decrease': 0.03,\n",
       " 'fed': 0.01,\n",
       " 'emirate': 0.01,\n",
       " 'tariff': 0.01,\n",
       " 'energy': 0.01,\n",
       " 'overseas': 0.01,\n",
       " 'office': 0.01,\n",
       " 'new': 0.03,\n",
       " 'plant': 0.01,\n",
       " 'newspaper': 0.01,\n",
       " 'officials': 0.01,\n",
       " 'dealers': 0.01,\n",
       " 'last': 0.01,\n",
       " 'turkish': 0.01,\n",
       " 'same': 0.01,\n",
       " 'increase': 0.1,\n",
       " 'commerzbank': 0.01,\n",
       " 'bulk': 0.01,\n",
       " 'traders': 0.01,\n",
       " 'csce': 0.02,\n",
       " 'exchange': 0.01,\n",
       " 'supreme': 0.01,\n",
       " 'buena': 0.01,\n",
       " 'move': 0.02,\n",
       " 'benchmark': 0.01,\n",
       " 'sale': 0.01,\n",
       " 'transaction': 0.01,\n",
       " 'house': 0.01,\n",
       " 'options': 0.01,\n",
       " 'government': 0.01,\n",
       " 'higher': 0.01,\n",
       " 'official': 0.01,\n",
       " 'pound': 0.01,\n",
       " 'storm': 0.01,\n",
       " 'canadian': 0.01,\n",
       " 'average': 0.01,\n",
       " 'court': 0.01,\n",
       " 'usda': 0.01,\n",
       " 'redstone': 0.01,\n",
       " 'italian': 0.01,\n",
       " 'agriculture': 0.01,\n",
       " 'focus': 0.01,\n",
       " 'economic': 0.01,\n",
       " 'china': 0.01,\n",
       " 'planes': 0.01,\n",
       " 'third': 0.01,\n",
       " 'commission': 0.01,\n",
       " 'auditors': 0.01,\n",
       " 'tax': 0.01,\n",
       " 'u': 0.01,\n",
       " 'world': 0.01,\n",
       " 'time': 0.01,\n",
       " 'seamen': 0.01,\n",
       " 'federal': 0.01}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model['today','the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bi = defaultdict(lambda : defaultdict(lambda : 0))\n",
    "ngram_bi = generate_ngrams(snew,2)\n",
    "model_mono = defaultdict(lambda : 0)\n",
    "ngram_mono = generate_ngrams(snew,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ngram_bi)):\n",
    "    [w1, w2] = ngram_bi[i].split()\n",
    "    model_bi[w1][w2] += 1\n",
    "\n",
    "for w1 in model_bi:\n",
    "    total_count = float(sum(model_bi[w1].values()))\n",
    "    for w2 in model_bi[w1]:\n",
    "        model_bi[w1][w2] = round((model_bi[w1][w2] / total_count),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in': 0.07,\n",
       " 'vs': 0.15,\n",
       " 'company': 0.0,\n",
       " 'per': 0.06,\n",
       " 'and': 0.02,\n",
       " 'from': 0.09,\n",
       " 'a': 0.01,\n",
       " 'nominal': 0.01,\n",
       " 'de': 0.0,\n",
       " 'the': 0.03,\n",
       " 'at': 0.02,\n",
       " 'of': 0.03,\n",
       " 'during': 0.01,\n",
       " 'last': 0.02,\n",
       " 'after': 0.02,\n",
       " 'against': 0.04,\n",
       " 'sight': 0.01,\n",
       " 'to': 0.07,\n",
       " 'this': 0.0,\n",
       " 'with': 0.01,\n",
       " 'on': 0.02,\n",
       " 'could': 0.0,\n",
       " 'french': 0.01,\n",
       " '396': 0.0,\n",
       " 'dividend': 0.0,\n",
       " 'south': 0.0,\n",
       " 'pancontinental': 0.0,\n",
       " 'fob': 0.0,\n",
       " 'no': 0.0,\n",
       " 'including': 0.0,\n",
       " 'note': 0.0,\n",
       " 'which': 0.0,\n",
       " 'each': 0.01,\n",
       " 'doubling': 0.0,\n",
       " 'into': 0.0,\n",
       " 'earlier': 0.0,\n",
       " 'he': 0.0,\n",
       " '1': 0.0,\n",
       " '65': 0.0,\n",
       " '24': 0.0,\n",
       " 'end': 0.0,\n",
       " 'through': 0.0,\n",
       " 'resulting': 0.0,\n",
       " 'reserves': 0.0,\n",
       " 'sl': 0.0,\n",
       " 'societe': 0.0,\n",
       " 'would': 0.0,\n",
       " 'geronimus': 0.0,\n",
       " 'had': 0.0,\n",
       " 'for': 0.01,\n",
       " 'japan': 0.0,\n",
       " 'as': 0.0,\n",
       " 'but': 0.0,\n",
       " 'they': 0.0,\n",
       " 'while': 0.0,\n",
       " 'also': 0.0,\n",
       " 'carries': 0.0,\n",
       " 'pittston': 0.0,\n",
       " '32': 0.0,\n",
       " '16': 0.0,\n",
       " 'cash': 0.0,\n",
       " 'reported': 0.0,\n",
       " 'somewhat': 0.0,\n",
       " 'over': 0.01,\n",
       " 'compared': 0.01,\n",
       " 'jacobs': 0.0,\n",
       " 'was': 0.0,\n",
       " 'it': 0.0,\n",
       " 'president': 0.0,\n",
       " 'unchanged': 0.0,\n",
       " 'solv': 0.0,\n",
       " 'jan': 0.0,\n",
       " 'switzerland': 0.0,\n",
       " 'loss': 0.01,\n",
       " 'yesterday': 0.0,\n",
       " 'up': 0.0,\n",
       " 'instead': 0.0,\n",
       " 'by': 0.01,\n",
       " 'u': 0.01,\n",
       " 'via': 0.0,\n",
       " 'new': 0.0,\n",
       " 'without': 0.0,\n",
       " 'below': 0.0,\n",
       " 'chief': 0.0,\n",
       " 'martens': 0.0,\n",
       " 'will': 0.0,\n",
       " 'or': 0.0,\n",
       " 'unadjusted': 0.0,\n",
       " 'an': 0.0,\n",
       " '3': 0.0,\n",
       " 'seasonally': 0.0,\n",
       " 'under': 0.0,\n",
       " 'conditions': 0.0,\n",
       " 'entitled': 0.0,\n",
       " 'subtracted': 0.0,\n",
       " 'supplementary': 0.0,\n",
       " 'making': 0.0,\n",
       " 'due': 0.0,\n",
       " 'nestle': 0.0,\n",
       " 'lt': 0.0,\n",
       " 'operating': 0.0,\n",
       " 'then': 0.0,\n",
       " 'raising': 0.0,\n",
       " 'revised': 0.0,\n",
       " 'january': 0.0,\n",
       " 'notes': 0.0,\n",
       " 'tax': 0.0,\n",
       " 'worth': 0.01,\n",
       " 'foote': 0.0}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model_bi['francs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mono = defaultdict(lambda : 0)\n",
    "for i in range(len(ngram_mono)):\n",
    "    w1 = ngram_mono[i]\n",
    "    model_mono[w1] += 1\n",
    "\n",
    "total_count = float(sum(model_mono.values()))\n",
    "for w1 in model_mono:\n",
    "    model_mono[w1] = model_mono[w1] / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_1 = 0.45\n",
    "lambda_2 = 0.35\n",
    "lambda_3 = 0.20\n",
    "\n",
    "lambda_1 * dict(model[('asian','exporters')])['fear'] + lambda_2 * dict(model_bi['asian'])['exporters'] + lambda_3 * dict(model_mono)['asian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.399999999999999e-10"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_1 * dict(model[('the','impact')])['of']*dict(model['impact','of'])['brazil'] + lambda_2*dict(model_bi['the'])['impact']*dict(model_bi['impact'])['of']*dict(model_bi['of'])['brazil'] + lambda_3 * dict(model_mono)['the']* dict(model_mono)['impact']* dict(model_mono)['of']* dict(model_mono)['brazil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0058"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model['the','impact'])['of']*dict(model['impact','of'])['brazil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = snew.lower()\n",
    "s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "V=len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ngram_bi)):\n",
    "    [w1, w2] = ngram_bi[i].split()\n",
    "    model_bi[w1][w2] += 1\n",
    "\n",
    "for w1 in model_bi:\n",
    "    total_count = float(sum(model_bi[w1].values()))\n",
    "    for w2 in model_bi[w1]:\n",
    "        model_bi[w1][w2] = round(((model_bi[w1][w2]+1) / (total_count+V)),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.399999999999999e-10"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model_bi['the'])['impact']*dict(model_bi['impact'])['of']*dict(model_bi['of'])['brazil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
